{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BUwYda5ojN0p"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# print(tf.config.list_physical_devices('GPU'))\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb\n",
        "from pathlib import Path\n",
        "import ast\n",
        "from wfdb import processing\n",
        "from scipy.fftpack import fft, ifft\n",
        "import pywt as pw\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "import Preprocessing\n",
        "import FeatureExtraction\n",
        "from importlib import reload\n",
        "# import transformers\n",
        "import random\n",
        "# from transformers import Transformers\n",
        "import scipy.signal as signal\n",
        "from skimage.restoration import denoise_wavelet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eO02_EX3jx4z",
        "outputId": "82d787f6-ddda-4168-90f9-a4294700f8c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKrZHRRQjN0u"
      },
      "source": [
        "loading the signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro_opkYVjN0w"
      },
      "outputs": [],
      "source": [
        "reload(Preprocessing)\n",
        "\n",
        "load = Preprocessing.preprocess()\n",
        "x_train, y_train, x_test, y_test = load.loadData()\n",
        "\n",
        "origin_signals = np.zeros((19601, 12, 1000))\n",
        "origin_test_signals = np.zeros((2198, 12, 1000))\n",
        "\n",
        "for sig in range(x_train.shape[0]):\n",
        "    for lead in range(x_train.shape[2]):\n",
        "\n",
        "        origin_signals[sig, lead, :] = x_train[sig].T[lead][:]\n",
        "\n",
        "for sig in range(x_test.shape[0]):\n",
        "    for lead in range(x_test.shape[2]):\n",
        "\n",
        "        origin_test_signals[sig, lead, :] = x_test[sig].T[lead][:]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" highpassedfiltered are just baseline removed \"\"\"\n",
        "loaded_highpassedfiltered_signal = np.load('highpass_filtered.npy')\n",
        "\n",
        "\n",
        "\"\"\" 'bandpass_filtered.npy' contains signals that have been thourogh\n",
        "baseline removal + moving avg + bandpass filter [0.5 - 25] \"\"\"\n",
        "\n",
        "loaded_bandpassedfiltered_signal = np.load('bandpass_filtered_25.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpxNzc9BjN0y"
      },
      "source": [
        "Freq Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Vofh4kjN0y"
      },
      "outputs": [],
      "source": [
        "reload(transformers)\n",
        "T = Transformers()\n",
        "T.FFT(origin_signals[0][0][:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr5C4ZxujN0z"
      },
      "source": [
        "Noise-removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWSab4UpjN0z"
      },
      "outputs": [],
      "source": [
        "reload(Preprocessing)\n",
        "\n",
        "\"\"\" all the filtering techniques are applied to the train signals \"\"\"\n",
        "filter = Preprocessing.preprocess()\n",
        "\n",
        "baseline_removed_signals, bandpassfiltered_signals, smoothedfiltered_signals = np.zeros((19601, 12, 1000)), np.zeros((19601, 12, 1000)), np.zeros((19601, 12, 1000))\n",
        "\n",
        "\n",
        "for sig in range(origin_signals.shape[0]):\n",
        "    for lead in range(origin_signals.shape[1]):\n",
        "\n",
        "\n",
        "        \"\"\" baseline removal \"\"\"\n",
        "        baseline_removed_signals[sig][lead] = filter.highpassfilter(origin_signals[sig][lead][:], 100, 4, 0.5)\n",
        "\n"
      ]
    },
=======
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from pathlib import Path\n",
    "import ast\n",
    "from wfdb import processing\n",
    "from scipy.fftpack import fft, ifft \n",
    "import pywt as pw\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "import Preprocessing\n",
    "import FeatureExtraction\n",
    "from importlib import reload\n",
    "import transformers\n",
    "import random\n",
    "from transformers import Transformers\n",
    "import scipy.signal as signal\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from scipy.stats import skew, kurtosis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 'bandpass_filtered.npy' contains signals that have been thourogh \\nbaseline removal + moving avg + bandpass filter [0.5 - 25] \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(Preprocessing)\n",
    "\n",
    "load = Preprocessing.preprocess()\n",
    "x_train, y_train, x_test, y_test = load.loadData()\n",
    "\n",
    "\n",
    "\"\"\" a 3D array of shape (19601, 12, 1000) where the first dimension represents the number of ECG signals,\n",
    " the second dimension represents the number of leads, and the third dimension represents the length of each signal. \"\"\"\n",
    "\n",
    "\n",
    " \n",
    "origin_signals = np.zeros((19601, 12, 1000))\n",
    "origin_test_signals = np.zeros((2198, 12, 1000))\n",
    "\n",
    "for sig in range(x_train.shape[0]):\n",
    "    for lead in range(x_train.shape[2]):\n",
    "        \n",
    "        origin_signals[sig, lead, :] = x_train[sig].T[lead][:] \n",
    "\n",
    "for sig in range(x_test.shape[0]):\n",
    "    for lead in range(x_test.shape[2]):\n",
    "        \n",
    "        origin_test_signals[sig, lead, :] = x_test[sig].T[lead][:] \n",
    "\n",
    "\n",
    "\n",
    "\"\"\" highpassedfiltered are just baseline removed \"\"\"\n",
    "# loaded_highpassedfiltered_signal = np.load('highpass_filtered.npy')\n",
    "\n",
    "\n",
    "\"\"\" 'bandpass_filtered.npy' contains signals that have been thourogh \n",
    "baseline removal + moving avg + bandpass filter [0.5 - 25] \"\"\" \n",
    "\n",
    "# loaded_bandpassedfiltered_signal = np.load('bandpass_filtered_25.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freq Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(transformers)\n",
    "T = Transformers()\n",
    "T.FFT(origin_signals[0][0][:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise-removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Preprocessing)\n",
    "\n",
    "\"\"\" all the filtering techniques are applied to the train signals \"\"\"\n",
    "filter = Preprocessing.preprocess()\n",
    "\n",
    "baseline_removed_signals, bandpassfiltered_signals, smoothedfiltered_signals = np.zeros((19601, 12, 1000)), np.zeros((19601, 12, 1000)), np.zeros((19601, 12, 1000))\n",
    "\n",
    "\n",
    "for sig in range(origin_signals.shape[0]):\n",
    "    for lead in range(origin_signals.shape[1]):\n",
    "        \n",
    "\n",
    "        \"\"\" baseline removal \"\"\"\n",
    "        baseline_removed_signals[sig][lead] = filter.highpassfilter(origin_signals[sig][lead][:], 100, 4, 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
>>>>>>> fc1f066 (	modified:   FeatureExtraction.py)
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-fVSaLrjN00",
        "outputId": "662ad584-fe60-4e68-8509-04598d23d44f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/donya/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/donya/.local/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "\"\"\" smoothing using wavelets\n",
        "this changes have been applied to the baseline filtered signals \"\"\"\n",
        "\n",
        "reload(Preprocessing)\n",
        "filter = Preprocessing.preprocess()\n",
        "waveletfiltered_signals = np.zeros((19601, 12, 1000))\n",
        "\n",
        "\n",
        "for sig in range(origin_signals.shape[0]):\n",
        "    for lead in range(origin_signals.shape[1]):\n",
        "\n",
        "        waveletfiltered_signals[sig][lead] = filter.wavelet_denoising(loaded_highpassedfiltered_signal[sig][lead][:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqdz6NnmjN01"
      },
      "outputs": [],
      "source": [
        "for sig in range(origin_signals.shape[0]):\n",
        "    for lead in range(origin_signals.shape[1]):\n",
        "\n",
        "        smoothedfiltered_signals[sig][lead] = filter.movingaveragefilter(origin_signals[sig][lead][:])\n",
        "\n",
        "np.save('movingavg_filtered.npy', bandpassfiltered_signals)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-CJLmRUjN02"
      },
      "outputs": [],
      "source": [
        "\n",
        "for sig in range(origin_signals.shape[0]):\n",
        "    for lead in range(origin_signals.shape[1]):\n",
        "\n",
        "        \"\"\" smoothing the variations \"\"\"\n",
        "        bandpassfiltered_signals[sig][lead] = filter.bandpassfilter(baseline_removed_signals[sig][lead][:], 100, 4, 0.5, 35)\n",
        "\n",
        "# np.save('bandpass_filtered.npy', bandpassfiltered_signals)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWFqfXV_jN02"
      },
      "outputs": [],
      "source": [
        "reload(Preprocessing)\n",
        "show = Preprocessing.preprocess()\n",
        "\n",
        "show.noise_representation(waveletfiltered_signals[0][0], waveletfiltered_signals[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpdrETKOjN03"
      },
      "source": [
        "Extracting Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCmqNl0ljN03"
      },
      "outputs": [],
      "source": [
        "\"\"\" locating the R Peak for the entire dataset\n",
        "the output is a 2D list that each [19601 rows] row contains the R peak locations for a signal \"\"\"\n",
        "\n",
        "reload(FeatureExtraction)\n",
        "extractor = FeatureExtraction.QRS()\n",
        "R_peaks = []\n",
        "loaded_waveletfiltered_signals = np.load('/content/drive/MyDrive/ECG/wavelet_filtered.npy')\n",
        "for sig in range(loaded_waveletfiltered_signals.shape[0]):\n",
        "    for lead in range(loaded_waveletfiltered_signals.shape[1]):\n",
        "\n",
        "        R_peak = extractor.R_peak_detection(loaded_waveletfiltered_signals[sig][lead])\n",
        "        R_peaks.append(R_peak)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RbamUOJjN04"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    }
<<<<<<< HEAD
=======
   ],
   "source": [
    "\"\"\" smoothing using wavelets\n",
    "this changes have been applied to the baseline filtered signals \"\"\"\n",
    "\n",
    "reload(Preprocessing)\n",
    "filter = Preprocessing.preprocess()\n",
    "waveletfiltered_signals = np.zeros((19601, 12, 1000))\n",
    "\n",
    "\n",
    "for sig in range(origin_signals.shape[0]):\n",
    "    for lead in range(origin_signals.shape[1]):\n",
    "\n",
    "        waveletfiltered_signals[sig][lead] = filter.wavelet_denoising(loaded_highpassedfiltered_signal[sig][lead][:])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig in range(origin_signals.shape[0]):\n",
    "    for lead in range(origin_signals.shape[1]):\n",
    "\n",
    "        smoothedfiltered_signals[sig][lead] = filter.movingaveragefilter(origin_signals[sig][lead][:])\n",
    "\n",
    "np.save('movingavg_filtered.npy', bandpassfiltered_signals)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sig in range(origin_signals.shape[0]):\n",
    "    for lead in range(origin_signals.shape[1]):\n",
    "\n",
    "        \"\"\" smoothing the variations \"\"\"\n",
    "        bandpassfiltered_signals[sig][lead] = filter.bandpassfilter(baseline_removed_signals[sig][lead][:], 100, 4, 0.5, 35)\n",
    "\n",
    "# np.save('bandpass_filtered.npy', bandpassfiltered_signals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Preprocessing)\n",
    "show = Preprocessing.preprocess()\n",
    "\n",
    "show.noise_representation(loaded_waveletfiltered_signals[0][0], loaded_waveletfiltered_signals[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "locating the R Peaks for the entire dataset\n",
    "- R_peaks should have a shape of (19601, 12), representing the R peak locations for each signal and lead.\n",
    "- RR_intervals should have a shape of (19601, 12), representing the RR intervals for each signal and lead. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reload(FeatureExtraction)\n",
    "extractor = FeatureExtraction.QRS()\n",
    "\n",
    "loaded_waveletfiltered_signals = np.load('wavelet_filtered.npy')\n",
    "R_peaks = []\n",
    "\n",
    "for signal in loaded_waveletfiltered_signals:\n",
    "    signal_r_peaks = []\n",
    "    for lead in signal:\n",
    "        r_peaks = extractor.R_peak_detection(lead)\n",
    "        signal_r_peaks.append(r_peaks)\n",
    "    R_peaks.append(signal_r_peaks)\n",
    "\n",
    "RR_intervals = [[np.diff(lead) / extractor.sampling_rate for lead in signal] for signal in R_peaks]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
>>>>>>> fc1f066 (	modified:   FeatureExtraction.py)
  },
  "nbformat": 4,
  "nbformat_minor": 0
}